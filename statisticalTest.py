import numpy as np
from scipy.stats import wilcoxon

# Input the CV_List metric values from the first model here.
BaselineAuc = [np.float64(0.7692147034252297), np.float64(0.7391114982578397), np.float64(0.7477099236641221), np.float64(0.7531135531135531), np.float64(0.7209645669291338), np.float64(0.7695094760312152), np.float64(0.7541703248463565), np.float64(0.6977671451355661), np.float64(0.7263993316624896), np.float64(0.7977941176470589)]
BaselineAccuracy = [0.6357615894039735, 0.6423841059602649, 0.6357615894039735, 0.609271523178808, 0.6158940397350994, 0.6423841059602649, 0.609271523178808, 0.6291390728476821, 0.6026490066225165, 0.6357615894039735]
BaselinePrecision = [0.6134683098591549, 0.6444736842105263, 0.6142605633802817, 0.621355813136635, 0.6181578947368421, 0.5864937388193202, 0.6016146016146016, 0.5881307746979388, 0.5951210951210951, 0.6071428571428571]
BaselineRecall = [0.7692147034252297, 0.7391114982578397, 0.7477099236641221, 0.7531135531135531, 0.7209645669291338, 0.7695094760312151, 0.7541703248463565, 0.6977671451355663, 0.7263993316624895, 0.7977941176470589]
BaselineF1 = [0.561903254734399, 0.6040209790209791, 0.5674704442476954, 0.556700004975867, 0.5664356435643564, 0.5333104395604396, 0.5360137492838914, 0.5447889750215331, 0.531055900621118, 0.5497424776362158]

# Input the CV_List metrric values from the second model here.
NewAuc = [np.float64(0.5758145363408521), np.float64(0.5949477351916376), np.float64(0.7347328244274809), np.float64(0.5529304029304029), np.float64(0.5805446194225721), np.float64(0.7235228539576367), np.float64(0.6321334503950835), np.float64(0.5637958532695375), np.float64(0.6276106934001671), np.float64(0.7409313725490194)]
NewAccuracy = [0.8874172185430463, 0.8344370860927153, 0.9072847682119205, 0.8145695364238411, 0.8344370860927153, 0.9403973509933775, 0.8940397350993378, 0.8675496688741722, 0.8940397350993378, 0.9072847682119205]
NewPrecision = [0.7486301369863013, 0.755868544600939, 0.8206465067778936, 0.5708333333333333, 0.6594155844155845, 0.8505244755244755, 0.7355242566510172, 0.6587301587301587, 0.7670454545454546, 0.7409313725490196]
NewRecall = [0.5758145363408521, 0.5949477351916376, 0.7347328244274809, 0.552930402930403, 0.5805446194225722, 0.7235228539576366, 0.6321334503950834, 0.5637958532695375, 0.6276106934001671, 0.7409313725490196]
NewF1 = [0.5999688327879071, 0.6149923508414075, 0.767998244073749, 0.5584795321637427, 0.5960406634563937, 0.7697000508388409, 0.6633221850613155, 0.5791527313266444, 0.6633221850613155, 0.7409313725490196]





#print('base:',len(Baseline_Values),'new:',len(New_Values))


Baseline_Values = {
    "Auc": BaselineAuc,
    "Accuracy": BaselineAccuracy,
    "Precision": BaselinePrecision,
    "Recall": BaselineRecall,
    "F1": BaselineF1
}
New_Values = {
    "Auc": NewAuc,
    "Accuracy": NewAccuracy,
    "Precision": NewPrecision,
    "Recall": NewRecall,
    "F1": NewF1
}


print('Test Results:')


for metric in Baseline_Values.keys():
    stat, p_value = wilcoxon(Baseline_Values[metric], New_Values[metric])
    print(f'Test Statistic: {stat:.4f}')
    print(f"P-value: {p_value:.4f}")

    if p_value < 0.05:
        print(f'ðŸŸ¢ The difference in {metric} is statistically significant (p < 0.05)')
        print('The new model significantly outperforms the Baseline')
    else:
        print(f'ðŸ”´ No statistically significant difference in {metric} (p >= 0.05)')
        print('The difference could be due to random chance.')







