import numpy as np
from scipy.stats import wilcoxon

# Input the CV_List metric values from the first model here.
BaselineAuc = [np.float64(0.7328469884025439), np.float64(0.7345931997571342), np.float64(0.7171666666666667), np.float64(0.6995833333333333), np.float64(0.6961466517022072), np.float64(0.7199193548387097), np.float64(0.7336404914529915), np.float64(0.73), np.float64(0.7381160369804178), np.float64(0.7247356774034914)]
BaselineAccuracy = [0.587248322147651, 0.5771812080536913, 0.5536912751677853, 0.5100671140939598, 0.5503355704697986, 0.5604026845637584, 0.5906040268456376, 0.5469798657718121, 0.587248322147651, 0.5536912751677853]
BaselinePrecision = [0.6442343344456805, 0.6447097378277153, 0.6216790400149415, 0.6176788522012578, 0.6237899608065354, 0.6273287575290657, 0.6668096872616324, 0.6311475409836066, 0.6531367041198501, 0.6290960451977401]
BaselineRecall = [0.7328469884025439, 0.7345931997571342, 0.7171666666666667, 0.6995833333333333, 0.6961466517022072, 0.7199193548387097, 0.7336404914529915, 0.73, 0.7381160369804178, 0.7247356774034915]
BaselineF1 = [0.5638661161548255, 0.5553713527851459, 0.5251991614255765, 0.4907771535580524, 0.5299905838041431, 0.5339469694256413, 0.5787449017426771, 0.5228607009428927, 0.5679377615371015, 0.5284080768178194]

# Input the CV_List metrric values from the second model here.
NewAuc = [np.float64(0.7248784137673026), np.float64(0.6894353369763205), np.float64(0.7244166666666668), np.float64(0.7488333333333332), np.float64(0.7447811447811447), np.float64(0.757741935483871), np.float64(0.7250934829059829), np.float64(0.6995833333333334), np.float64(0.7387348038145155), np.float64(0.7291615441357266)]
NewAccuracy = [0.87248322147651, 0.8456375838926175, 0.8624161073825504, 0.889261744966443, 0.8590604026845637, 0.8758389261744967, 0.8624161073825504, 0.8489932885906041, 0.8590604026845637, 0.8624161073825504]
NewPrecision = [0.8112250181215699, 0.741860465116279, 0.7455996352029184, 0.8092057574816196, 0.7681337595279076, 0.7807202459376372, 0.8337293337293337, 0.718422252621979, 0.7779944053572942, 0.7501789549033644]
NewRecall = [0.7248784137673027, 0.6894353369763206, 0.7244166666666667, 0.7488333333333332, 0.7447811447811448, 0.7577419354838709, 0.725093482905983, 0.6995833333333333, 0.7387348038145156, 0.7291615441357266]
NewF1 = [0.7557798481711526, 0.7095024158684411, 0.7341312153193342, 0.7735927247611374, 0.7553939962476548, 0.7683370101901461, 0.7593887236849879, 0.7081927973017081, 0.7553939962476548, 0.7388144252762991]





#print('base:',len(Baseline_Values),'new:',len(New_Values))


Baseline_Values = {
    "Auc": BaselineAuc,
    "Accuracy": BaselineAccuracy,
    "Precision": BaselinePrecision,
    "Recall": BaselineRecall,
    "F1": BaselineF1
}
New_Values = {
    "Auc": NewAuc,
    "Accuracy": NewAccuracy,
    "Precision": NewPrecision,
    "Recall": NewRecall,
    "F1": NewF1
}


print('Test Results:')


for metric in Baseline_Values.keys():
    stat, p_value = wilcoxon(Baseline_Values[metric], New_Values[metric])
    print(f'Test Statistic: {stat:.4f}')
    print(f"P-value: {p_value:.4f}")

    if p_value < 0.05:
        print(f'ðŸŸ¢ The difference in {metric} is statistically significant (p < 0.05)')
        print('The new model significantly outperforms the Baseline')
    else:
        print(f'ðŸ”´ No statistically significant difference in {metric} (p >= 0.05)')
        print('The difference could be due to random chance.')







